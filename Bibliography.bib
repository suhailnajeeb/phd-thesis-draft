@article{Reference1,
	Abstract = {We have developed an enhanced Littrow configuration extended cavity diode laser (ECDL) that can be tuned without changing the direction of the output beam. The output of a conventional Littrow ECDL is reflected from a plane mirror fixed parallel to the tuning diffraction grating. Using a free-space Michelson wavemeter to measure the laser wavelength, we can tune the laser over a range greater than 10 nm without any alteration of alignment.},
	Author = {C. J. Hawthorn and K. P. Weber and R. E. Scholten},
	Journal = {Review of Scientific Instruments},
	Month = {December},
	Number = {12},
	Numpages = {3},
	Pages = {4477--4479},
	Title = {Littrow Configuration Tunable External Cavity Diode Laser with Fixed Direction Output Beam},
	Volume = {72},
	Url = {http://link.aip.org/link/?RSI/72/4477/1},
	Year = {2001}}

@article{Reference3,
	Abstract = {Operating a laser diode in an extended cavity which provides frequency-selective feedback is a very effective method of reducing the laser's linewidth and improving its tunability. We have developed an extremely simple laser of this type, built from inexpensive commercial components with only a few minor modifications. A 780~nm laser built to this design has an output power of 80~mW, a linewidth of 350~kHz, and it has been continuously locked to a Doppler-free rubidium transition for several days.},
	Author = {A. S. Arnold and J. S. Wilson and M. G. Boshier},
	Journal = {Review of Scientific Instruments},
	Month = {March},
	Number = {3},
	Numpages = {4},
	Pages = {1236--1239},
	Title = {A Simple Extended-Cavity Diode Laser},
	Volume = {69},
	Url = {http://link.aip.org/link/?RSI/69/1236/1},
	Year = {1998}}

@article{Reference2,
	Abstract = {We present a review of the use of diode lasers in atomic physics with an extensive list of references. We discuss the relevant characteristics of diode lasers and explain how to purchase and use them. We also review the various techniques that have been used to control and narrow the spectral outputs of diode lasers. Finally we present a number of examples illustrating the use of diode lasers in atomic physics experiments. Review of Scientific Instruments is copyrighted by The American Institute of Physics.},
	Author = {Carl E. Wieman and Leo Hollberg},
	Journal = {Review of Scientific Instruments},
	Keywords = {Diode Laser},
	Month = {January},
	Number = {1},
	Numpages = {20},
	Pages = {1--20},
	Title = {Using Diode Lasers for Atomic Physics},
	Volume = {62},
	Url = {http://link.aip.org/link/?RSI/62/1/1},
	Year = {1991}}

## Section 2.1

@inproceedings{viola2001rapid,
  title={Rapid Object Detection using a Boosted Cascade of Simple Features},
  author={Viola, Paul and Jones, Michael},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2001}
}

@inproceedings{dalal2005hog,
  title={Histograms of Oriented Gradients for Human Detection},
  author={Dalal, Navneet and Triggs, Bill},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2005}
}

@article{felzenszwalb2010dpm,
  title={Object Detection with Discriminatively Trained Part-Based Models},
  author={Felzenszwalb, Pedro F. and Girshick, Ross B. and McAllester, David and Ramanan, Deva},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2010}
}

@inproceedings{girshick2014rcnn,
  title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@inproceedings{girshick2015fastrcnn,
  title={Fast R-CNN},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2015}
}

@inproceedings{ren2015fasterrcnn,
  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2015}
}

@inproceedings{he2017maskrcnn,
  title={Mask R-CNN},
  author={He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}

@inproceedings{redmon2016yolov1,
  title={You Only Look Once: Unified, Real-Time Object Detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@inproceedings{redmon2017yolov2,
  title={YOLO9000: Better, Faster, Stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@article{redmon2018yolov3,
  title={YOLOv3: An Incremental Improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@article{bochkovskiy2020yolov4,
  title={YOLOv4: Optimal Speed and Accuracy of Object Detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@misc{jocher2020yolov5,
  title={YOLOv5},
  author={Jocher, Glenn and others},
  howpublished={Ultralytics repository},
  year={2020}
}

@article{liu2016ssd,
  title={SSD: Single Shot MultiBox Detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
  journal={arXiv preprint arXiv:1512.02325},
  year={2016}
}

@inproceedings{lin2017focalloss,
  title={Focal Loss for Dense Object Detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollar, Piotr},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}

@inproceedings{lin2017fpn,
  title={Feature Pyramid Networks for Object Detection},
  author={Lin, Tsung-Yi and Dollar, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{liu2018panet,
  title={Path Aggregation Network for Instance Segmentation},
  author={Liu, Shu and Qi, Lu and Qin, Haifang and Shi, Jianping and Jia, Jiaya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2018}
}

@inproceedings{tan2020efficientdet,
  title={EfficientDet: Scalable and Efficient Object Detection},
  author={Tan, Mingxing and Pang, Ruoming and Le, Quoc V.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020}
}

@inproceedings{liu2022convnext,
  title={A ConvNet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022}
}

@article{woo2023convnextv2,
  title={ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders},
  author={Woo, Sanghyun and others},
  journal={arXiv preprint arXiv:2301.00808},
  year={2023}
}

@inproceedings{ding2021repvgg,
  title={RepVGG: Making VGG-style ConvNets Great Again},
  author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{luo2016erf,
  title={Understanding the Effective Receptive Field in Deep Convolutional Neural Networks},
  author={Luo, Wenjie and Li, Yujia and Urtasun, Raquel and Zemel, Richard},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2016}
}

@inproceedings{geirhos2019texturebias,
  title={ImageNet-trained CNNs are Biased Towards Texture; Increasing Shape Bias Improves Accuracy and Robustness},
  author={Geirhos, Robert and Rubisch, Patryk and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A. and Brendel, Wieland},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{carion2020detr,
  title={End-to-End Object Detection with Transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2020}
}

@article{ge2024yolov9,
  title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information},
  author={Ge, Chien-Yao and others},
  journal={arXiv preprint arXiv:2402.13616},
  year={2024}
}

@article{wang2024yolov10,
  title={YOLOv10: Real-Time End-to-End Object Detection},
  author={Wang, Chien-Yao and others},
  journal={arXiv preprint arXiv:2405.14458},
  year={2024}
}

@article{ultralytics2024yolov11,
  title={YOLOv11: An Overview of Key Architectural Enhancements},
  author={Ultralytics Team},
  journal={arXiv preprint arXiv:2410.17725},
  year={2024}
}

@misc{ultralytics2025yolov12,
  title={YOLO12: Attention-Centric Object Detection},
  author={Ultralytics Team},
  howpublished={Ultralytics documentation},
  year={2025}
}

## Section 2.1 Ends

## Section 2.2 Starts

@inproceedings{vaswani2017attention,
  title     = {Attention Is All You Need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and others},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2017}
}

@inproceedings{wang2018nonlocal,
  title     = {Non-local Neural Networks},
  author    = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018}
}

@inproceedings{dosovitskiy2021vit,
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author    = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and others},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021}
}

@inproceedings{liu2021swin,
  title     = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author    = {Liu, Ze and Lin, Yutong and Cao, Yue and others},
  booktitle = {IEEE International Conference on Computer Vision (ICCV)},
  year      = {2021}
}

@article{wang2021pvt,
  title   = {Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},
  author  = {Wang, Wenhai and Xie, Enze and Li, Xiang and others},
  journal = {arXiv preprint arXiv:2102.12122},
  year    = {2021}
}

@inproceedings{wang2022pvtv2,
  title     = {PVTv2: Improved Baselines with Pyramid Vision Transformer},
  author    = {Wang, Wenhai and Xie, Enze and Li, Xiang and others},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022}
}

@inproceedings{he2022mae,
  title     = {Masked Autoencoders Are Scalable Vision Learners},
  author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and others},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022}
}

@inproceedings{li2022vitdet,
  title     = {Exploring Plain Vision Transformer Backbones for Object Detection},
  author    = {Li, Yanghao and Zhang, Hanzi and others},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2022}
}

@inproceedings{carion2020detr,
  title     = {End-to-End Object Detection with Transformers},
  author    = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and others},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2020}
}

@article{zhu2021deformabledetr,
  title   = {Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author  = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and others},
  journal = {arXiv preprint arXiv:2010.04159},
  year    = {2021}
}

@article{zhu2021deformable,
  title   = {Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author  = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and others},
  journal = {arXiv preprint arXiv:2010.04159},
  year    = {2021}
}

@article{oquab2023dinov2,
  title   = {DINOv2: Learning Robust Visual Features without Supervision},
  author  = {Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and others},
  journal = {arXiv preprint arXiv:2304.07193},
  year    = {2023}
}

@article{liu2024visionmamba,
  title   = {Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model},
  author  = {Liu, Feng and others},
  journal = {arXiv preprint arXiv:2401.09417},
  year    = {2024}
}

@inproceedings{hatamizadeh2025mambavision,
  title     = {MambaVision: A Hybrid Mamba-Transformer Vision Backbone},
  author    = {Hatamizadeh, Ali and others},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025}
}

## Section 2.2 Ends

## Section 2.3 Starts

@inproceedings{carion2020detr,
  title     = {End-to-End Object Detection with Transformers},
  author    = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2020}
}

@inproceedings{zhu2021deformabledetr,
  title     = {Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author    = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021}
}

@inproceedings{meng2021conditionaldetr,
  title     = {Conditional DETR for Fast Training Convergence},
  author    = {Meng, Dequan and Chen, Xiaokang and Fan, Zejia and Liang, Dongdong and others},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2021}
}

@inproceedings{liu2022dabdetr,
  title     = {DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR},
  author    = {Liu, Shilong and Li, Feng and Zhang, Hao and others},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2022}
}

@inproceedings{li2022dndetr,
  title     = {DN-DETR: Accelerate DETR Training by Introducing Query De-Noising},
  author    = {Li, Feng and Zhang, Hao and Liu, Shilong and others},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022}
}

@inproceedings{zhang2022dino,
  title     = {DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection},
  author    = {Zhang, Hao and Li, Feng and Liu, Shilong and others},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2023}
}

@article{sparse_detr_roh,
  title   = {Sparse DETR: Efficient End-to-End Object Detection with Sparse Tokens},
  author  = {Roh, Byungseok and others},
  journal = {arXiv preprint},
  year    = {2022}
}

@inproceedings{Lite_DETR_Li,
  title     = {Lite DETR: An Efficient Deformable Transformer for Object Detection},
  author    = {Li, Xiang and others},
  booktitle = {Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year      = {2022}
}

@inproceedings{EfficientDETR_yao,
  title     = {Efficient DETR: Improving End-to-End Object Detector with Dense Priors},
  author    = {Yao, Zhaohui and others},
  booktitle = {Asian Conference on Computer Vision (ACCV)},
  year      = {2022}
}

@inproceedings{chen2023groupdetr,
  title     = {Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment},
  author    = {Chen, Hao and Sun, Peize and Song, Xuyang and others},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2023}
}

@inproceedings{zong2023codetr,
  title     = {DETRs with Collaborative Hybrid Assignments Training},
  author    = {Zong, Zhibo and Zhang, Hao and Li, Feng and others},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2023}
}

@inproceedings{zhao2024msdetr,
  title     = {MS-DETR: Efficient DETR Training with Mixed Supervision},
  author    = {Zhao, Xinyu and others},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024}
}

@inproceedings{huang2025deim,
  title     = {DEIM: DETR with Improved Matching for Fast Convergence},
  author    = {Huang, Yiming and others},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025}
}

@inproceedings{hou2024relationdetr,
  title     = {Relation-DETR: Exploring Explicit Position Relation Prior for Object Detection},
  author    = {Hou, Yu and others},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2024}
}

@inproceedings{felix2024aligndetr,
  title     = {Align-DETR: Enhancing End-to-End Object Detection with Aligned Loss},
  author    = {Caae, Felix and others},
  booktitle = {British Machine Vision Conference (BMVC)},
  year      = {2024}
}

@inproceedings{nan2025midetr,
  title     = {MI-DETR: An Object Detection Model with Multi-time Inquiries Mechanism},
  author    = {Nan, Jiawei and others},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025}
}

@inproceedings{lv2023rtdetr,
  title     = {DETRs Beat YOLOs on Real-time Object Detection},
  author    = {Lv, Wenyu and Li, Feng and others},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2023}
}

@inproceedings{zhao2023rtdetr,
  title     = {DETRs Beat YOLOs on Real-time Object Detection},
  author    = {Yian Zhao and Wenyu Lv and Shangliang Xu and Jinman Wei and Guanzhong Wang and Qingqing Dang and Yi Liu and Jie Chen},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024},
  pages     = {â€“},        % please fill in actual page numbers if available
  doi       = {},         % please fill in DOI if available
}


@article{arxiv_rtdetr_beatyolo,
  title   = {DETRs Beat YOLOs on Real-time Object Detection},
  author  = {Lv, Wenyu and others},
  journal = {arXiv preprint},
  year    = {2023}
}

@article{medium_rtdetr_hybrid,
  title   = {RT-DETR: Hybrid Object Detection Model Combining Convolutions and Transformers},
  author  = {Cochard, David},
  journal = {Technical blog article},
  year    = {2024}
}

@inproceedings{wang2025rtdetrv3,
  title     = {RT-DETRv3: Real-time End-to-End Object Detection with Hierarchical Dense Positive Supervision},
  author    = {Wang, Yijiang and others},
  booktitle = {Winter Conference on Applications of Computer Vision (WACV)},
  year      = {2025}
}

@article{ccdn_detr_sar,
  title   = {CCDN-DETR: A Detection Transformer Based on Constrained Contrast Denoising for Multi-Class Synthetic Aperture Radar Object Detection},
  author  = {Chen, X. and others},
  journal = {Sensors},
  year    = {2024}
}

@inproceedings{sd_dino_correspondence,
  title     = {A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence},
  author    = {Kusupati, Aditya and others},
  booktitle = {Neural Information Processing Systems (NeurIPS)},
  year      = {2023}
}

## Section 2.3 Ends

## Section 2.4 Starts

@inproceedings{li2022vitdet,
title     = {Exploring Plain Vision Transformer Backbones for Object Detection},
author    = {Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
booktitle = {European Conference on Computer Vision (ECCV)},
year      = {2022}
}

@inproceedings{fang2021yolos,
title     = {You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection},
author    = {Fang, Yuxin and Liao, Bencheng and Wang, Xinggang and Fang, Jiemin and Qi, Jiyang and Wu, Rui and Niu, Jianwei and Liu, Wenyu},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year      = {2021}
}

@article{chen2022vitadapter,
title   = {Vision Transformer Adapter for Dense Predictions},
author  = {Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He, Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
journal = {arXiv preprint arXiv:2205.08534},
year    = {2022}
}

@article{liu2021swin,
title   = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
author  = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
journal = {arXiv preprint arXiv:2103.14030},
year    = {2021}
}

@inproceedings{wang2021pvt,
title     = {Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},
author    = {Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
booktitle = {International Conference on Computer Vision (ICCV)},
year      = {2021}
}

@article{wang2021pvtv2,
title   = {PVT v2: Improved Baselines with Pyramid Vision Transformer},
author  = {Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
journal = {arXiv preprint arXiv:2106.13797},
year    = {2021}
}

@article{song2021vidt,
title   = {ViDT: An Efficient and Effective Fully Transformer-based Object Detector},
author  = {Song, Hwanjun and Sun, Deqing and Chun, Sanghyuk and Jampani, Varun and Han, Dongyoon and Heo, Byeongho and Kim, Wonjae and Yang, Ming-Hsuan},
journal = {arXiv preprint arXiv:2110.03921},
year    = {2021}
}

@article{zhu2020deformable,
title   = {Deformable DETR: Deformable Transformers for End-to-End Object Detection},
author  = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
journal = {arXiv preprint arXiv:2010.04159},
year    = {2020}
}

@article{zhang2022dino,
title   = {DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection},
author  = {Zhang, Hao and Li, Feng and Liu, Shilong and Zhang, Lei and Su, Hang and Zhu, Jun and Ni, Lionel M. and Shum, Heung-Yeung},
journal = {arXiv preprint arXiv:2203.03605},
year    = {2022}
}

@inproceedings{he2022mae,
title     = {Masked Autoencoders Are Scalable Vision Learners},
author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{'a}r, Piotr and Girshick, Ross},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year      = {2022}
}


## Section 2.4 Ends

## Section 2.6 Starts

@article{detr_difficult_images2023,
  title        = {Investigating the Robustness and Properties of Detection Transformers toward Difficult Images},
  author       = {Authors to be confirmed},
  year         = {2023},
  eprint       = {2310.08772},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  note         = {arXiv:2310.08772}
}

@article{reliable_detr2024,
  title        = {Identifying Reliable Predictions in Detection Transformers},
  author       = {Authors to be confirmed},
  year         = {2024},
  eprint       = {2412.01782},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  note         = {arXiv:2412.01782}
}

@article{dg_detr2025,
  title        = {DG-DETR: Toward Domain Generalized Detection Transformer},
  author       = {Authors to be confirmed},
  year         = {2025},
  eprint       = {2504.19574},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  note         = {arXiv:2504.19574}
}

@inproceedings{chefer2021transformerinterpretability,
  title     = {Transformer Interpretability Beyond Attention Visualization},
  author    = {Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021}
}

@inproceedings{jain2019attentionnot,
  title     = {Attention is not Explanation},
  author    = {Jain, Sarthak and Wallace, Byron C.},
  booktitle = {Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year      = {2019}
}

## Section 2.6 Ends